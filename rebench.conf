default_experiment: all
default_data_file: 'benchmark.data'

benchmark_suites:
    awfy:
        gauge_adapter: RebenchLog
        command: " harness.lua %(benchmark)s %(iterations)s "
        max_invocation_time: 600 # seconds per vm invocation
        min_iteration_time: 200 # miliseconds per iteration
        invocations: 5 # the number of process executions
        iterations: 10 # the number of in-process iterations
        cores: [ "default" ]
        location: suites/awfy/Lua
        benchmarks: &BENCHMARKS
            - DeltaBlue:
                extra_args: 12000
            - Richards:
                extra_args: 100
            - Json:
                extra_args: 100
            - CD:
                extra_args: 250
            - Havlak:
                extra_args: 1500
            - Bounce:
                extra_args: 1500
            - List:
                extra_args: 1500
            - Mandelbrot:
                extra_args: 500
            - NBody:
                extra_args: 250000
            - Permute:
                extra_args: 1000
            - Queens:
                extra_args: 1000
            - Sieve:
                extra_args: 3000
            - Storage:
                extra_args: 1000
            - Towers:
                extra_args: 600
    # Benchmarks written "in-house".
    yk:
        gauge_adapter: RebenchLog
        # Borrowing the harness from awfy.
        command: " ../../awfy/Lua/harness.lua %(benchmark)s %(iterations)s "
        max_invocation_time: 600 # seconds per vm invocation
        min_iteration_time: 200 # miliseconds per iteration
        invocations: 5 # the number of process executions
        iterations: 10 # the number of in-process iterations
        cores: [ "default" ]
        location: suites/yk/Lua
        # ensure harness.lua can find its deps
        env: {LUA_PATH: "?.lua;../../awfy/Lua/?.lua"}
        benchmarks:
           - BigLoop:
               extra_args: 1000000000
    # Benchmarks based on real-world applications.
    realworld:
        gauge_adapter: RebenchLog
        # Borrowing the harness from awfy.
        command: " ../../awfy/Lua/harness.lua %(benchmark)s %(iterations)s "
        max_invocation_time: 600 # seconds per vm invocation
        min_iteration_time: 200 # miliseconds per iteration
        invocations: 5 # the number of process executions
        iterations: 10 # the number of in-process iterations
        cores: [ "default" ]
        location: suites/realworld/Lua
        # ensure harness.lua can find its deps
        env: {
            LUA_PATH: "?.lua;../../awfy/Lua/?.lua",
        }
        benchmarks:
          - LuLPeg
          - HashIds:
              extra_args: 6000
          - Heightmap:
              extra_args: 2000
    # Benchmarks based on the computer benchmarks game.
    cbgame:
        gauge_adapter: RebenchLog
        # Borrowing the harness from awfy.
        command: " ../../awfy/Lua/harness.lua %(benchmark)s %(iterations)s "
        max_invocation_time: 600 # seconds per vm invocation
        min_iteration_time: 200 # miliseconds per iteration
        invocations: 5 # the number of process executions
        iterations: 10 # the number of in-process iterations
        cores: [ "default" ]
        location: suites/cbgame/Lua
        # ensure harness.lua can find its deps
        env: {
            LUA_PATH: "?.lua;../../awfy/Lua/?.lua",
        }
        benchmarks:
          - fannkuchredux:
              extra_args: 10 # typically 12 (too slow)
          - spectralnorm:
              extra_args: 1000 # typically 100 (too fast)
          - knucleotide # uses fasta500000.txt as input
          - binarytrees:
              extra_args: 15 # typically 21 (too slow)

executors:
    Lua:
        executable: lua
        path: lua/src/
    YkLua:
        executable: yklua
        path: yklua/src/

experiments:
    yk:
        suites: [awfy, yk, realworld, cbgame]
        executions: [Lua, YkLua]
